defaults:
  - model: dit # or tread (both in dit.py)


dataset:
  name: imagenet256
  num_workers: 4
  total_num: 1281167
  num_classes: 1000
  resolution: 32
  num_channels: 4
  train_path: /export/scratch/ra63vex/MaskDiT/latent_imagenet_wds
  val_path: null
  ref_path: /export/scratch/ra63vex/MaskDiT/assets/fid_stats/VIRTUAL_imagenet256_labeled.npz

train:
  general:
    class_drop_prob: 0.1
    mask_ratio: 0.5 # this just needs to be > 0.0 for the mae loss to be used properly
    batch_size: 256
    max_epochs: 100000
    gradient_clipping_norm: null

  optimizer:
    _target_: torch.optim.AdamW
    lr: 1e-4
    betas: [0.9, 0.999]
    eps: 1e-08
    weight_decay: 0.0

  diffuser:
    _target_: edm.EDMDiffusion
    loss_type: mae # or simple for standard edm loss
    sampler_fn: sampling.edm_sampler

  logging:
    log_interval: 100

  eval:
    cfg_scales: [null]
    batchsize: 50
    eval_interval: 100
    fid_num_samples: 2_000
    fid_batch_size: 64
    seeds: '100000-149999'
    subdirs: False
    class_idx: null
    max_batch_size: 100
    cfg_scale: null
    num_steps: 40
    S_churn: 0
    solver: null
    discretization: null
    schedule: null
    scaling: null
    pretrained_path: /export/scratch/ra63vex/MaskDiT/assets/autoencoder_kl.pth
    inception_path: /export/scratch/ra63vex/MaskDiT/assets/inception-2015-12-05.pkl

wandb:
  project: test

results_dir: /export/scratch/ra63vex/dev/paper_codebases/tread/results
run_name: tread_2

hydra:  
  output_subdir: null  
  run:  
    dir: .

enable_eval: True
global_seed: 42
save_ckpt: False
load_ckpt: False
log_wandb: False